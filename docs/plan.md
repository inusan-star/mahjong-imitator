# 研究計画：不完全情報ゲームにおけるマルチラベル深層学習を用いた麻雀の役予測精度の向上

## 1. 実験設定 (Experimental Setup)

本研究では、評価の信頼性と再現性を担保するため、既存研究 [1] において詳細が不明瞭であったデータセット構築条件および予測対象ラベルを厳密に定式化する。

### 1.1 データセット構築 (Dataset Construction)

既存研究 [1] は役予測に関する先駆的な研究であるが、データセットの仕様に関する記述が一部欠落しており、同一条件での完全な再現が困難である。そこで本研究では、既存研究の不明瞭な点を補完し、以下の基準に基づいてデータセットを新規に構築する。

- **データソース:**
- **既存研究の記述:** オンライン麻雀サイト「天鳳」のトッププレイヤーの牌譜（Haifu）を使用し、学習に1,400,000レコード（局面データ）を使用したとされている 。しかし、具体的な対象期間や、何試合（半荘）分から抽出されたかについては明記されていない。

- **本研究の定義:** オンライン麻雀「天鳳」鳳凰卓の2024年全対局ログ（2024年1月1日〜2024年12月31日）をプールとする。

- **抽出条件 (Data Extraction):**
- **既存研究の記述:** 「現在の状況の情報を保存する」ために472次元の配列を使用したとあるが 、流局した局を学習データに含めているか、あるいは一局のうち「どのタイミング（全打牌時か、特定の巡目か）」をサンプリングしたかについての詳細な記述がない。

- **本研究の定義:**
- **対象局:** 和了（アガリ）が発生した局のみを抽出対象とする。流局および途中流局は、最終的な正解ラベル（完成形）が不確定であるため、学習データから除外する。
- **対象局面:** 和了したプレイヤーの視点における、配牌から和了直前までの「打牌選択時」および「副露（鳴き）選択時」の全ステップを学習サンプルとして抽出する。

- **データ分割 (Data Splitting):**
- **既存研究の記述:** データの10%を検証用データセット（Validation dataset）としたと記述されているが 、テストデータ（Test dataset）の存在や、分割方法（ランダム分割か、試合単位か）についての記述がない。

- **本研究の定義:** データ量の肥大化を防ぎつつ、役の出現分布の偏りを最小限に抑えるため、2024年のログから無作為に抽出した以下の試合数（半荘数）を使用する。同一半荘内の局面が学習・評価データ間で混在することによるリークを防ぐため、分割は必ず半荘単位で行う。
- **Train (学習):** 80,000 半荘
- **Valid (検証):** 10,000 半荘（モデル選択・ハイパーパラメータ調整用）
- **Test (評価):** 10,000 半荘（最終性能評価用）

### 1.2 予測対象ラベルの定義 (Target Label Definition)

麻雀の役には「手牌の構成によって論理的に確定するもの」と「他家の行動や偶然の事象に依存するもの」が混在している。本研究の目的は、AIエージェントの**「手牌構成の構想力 (Hand Structuring Capability)」**を評価することにあるため、偶然性を排除した以下の基準に基づき予測対象を選定する。

#### A. 予測対象とする役 (Included Targets: Structural & Volitional)

プレイヤーの意思決定および手牌構築によって制御可能な以下の**37種**を予測対象（正解ラベル）とする。

1. **構造的役 (Structural Yaku):** 手牌の面子構成によって成立する役。

- **1飜:** 断么九 (Tanyao)、平和 (Pinfu)、一盃口 (Iipeiko)、役牌（白・發・中・自風・場風）。
- **2飜:** 混全帯幺九 (Chanta)、一気通貫 (Itsu)、三色同順 (Sanshoku Doujun)、三色同刻 (Sanshoku Doukou)、三槓子 (Sankantsu)、対々和 (Toitoi)、三暗刻 (Sanankou)、小三元 (Shosangen)、混老頭 (Honroutou)、七対子 (Chiitoitsu)。
- **3飜以上:** 二盃口 (Ryanpeiko)、純全帯幺九 (Junchan)、混一色 (Honitsu)、清一色 (Chinitsu)。
- **役満:** 四暗刻、大三元、緑一色、字一色、小四喜、大四喜、清老頭、四槓子、九蓮宝燈、国士無双。
- ※役満は出現頻度が極めて低いが、手牌構造の完成形として明確な意図を要するため、除外せずに評価対象とする。

2. **意思表示役 (Volitional Yaku):** プレイヤーの宣言によって成立する役。

- **立直 (Reach):** リーチ宣言は重要な戦略的意思決定であるため対象とする。
- **両立直 (Double Reach):** 第1打での宣言という意思決定の結果であるため対象とする。

3. **可視的情報 (Visible Value):** 手作りの指針となる確定情報。

- **ドラ (Dora) / 赤ドラ (Red Dora):** 厳密には役ではないが、打点向上に不可欠な視認可能情報であるため、予測対象に含める。

#### B. 除外する役 (Excluded Targets: Event & Luck)

以下の役は、手牌の構造的完成度とは無関係な「外部事象」や「不可知情報」に依存するため、本研究の評価対象から除外する。これらを予測させることは、論理的推論ではなく確率的なノイズ学習を強いることになるためである。

1. **事象役 (Event Yaku):** 他家の打牌タイミングや巡目に依存するもの。

- **除外対象:** 一発、嶺上開花、槍槓、海底摸月、河底撈魚。

2. **不可知な役 (Hidden Information):** 対局終了まで物理的に視認できないもの。

- **除外対象:** 裏ドラ。

3. **純粋な偶然 (Pure Luck):** プレイヤーの操作が介在しないもの。

- **除外対象:** 天和、地和、人和（ローカル役扱いだが天鳳には存在するため明記）。

### 1.3 評価指標 (Metrics)

- **Macro F1-Score:** 役ごとの出現頻度は極めて不均衡（例: 断么九と三色同刻の差）であるため、単純な正解率 (Accuracy) ではなく、全クラスのF1スコアの算術平均を最重要指標とする。
- **Exact Match Ratio (Structural Accuracy):** 上記定義に基づき偶然役を除外した上で、予測した役の集合が正解ラベル集合と完全に一致したサンプルの割合。これを「構想の正確さ」と定義する。
- **Comparison Metrics:** 既存研究との比較のため、特定の主要9役（立直, 断么九, 役牌, 混一色, ドラ等）については Accuracy, Precision, Recall を算出する。

---

## 2. 実験詳細 (Methods & Experiments)

本研究では、既存研究の数値を単に追従するのではなく、前節で定義した「厳密化されたデータセット」上で手法の比較検証を行う。

### 【実験1】 現代的データセットにおけるベースラインの確立 (Baseline Establishment)

**目的:**
2024年の実データおよび厳密な評価定義（偶然役の排除）の下において、既存研究の手法（40モデル独立学習）がどの程度の性能を示すかを測定する。これを本研究における改善の出発点（Baseline）として確立する。

**手法:**

- **入力データ:** 既存研究 [1] に準拠した472次元配列（手牌34種×4、河34種×4、副露、ドラ表示牌、風、リーチ状況等のフラットな結合）。
- **モデル構造:** 全結合層 (Fully Connected Layers) 6層からなる多層パーセプトロン (MLP)。
- 各層のユニット数は既存研究の設定 [1] を再現する（512, 512, 256, 256, 256, 64）。
- **学習方式 (Binary Relevance):**
- **1.2** で定義した37種の予測対象役それぞれに対し、独立した2値分類モデル（合計37個のモデル）を作成し、個別に学習を行う。
- 最適化手法およびハイパーパラメータは、Validデータを用いて調整を行う。

**予想される結果と位置付け:**
既存研究 [1] において、特定の役（例：断么九）の予測精度は約79%（F1-score 約0.68）等の値が報告されている 。しかし、これらはデータセットの条件や評価対象（偶然役の扱いや役の総数）が異なる環境での数値である。したがって、本実験で得られた数値を、現代的なデータセットおよび本研究の定義下における、役予測タスクの正当なベースラインスコアとして新たに定義する。

### 【実験2】 マルチラベル学習による役間相関の獲得と効率化 (Multi-label Learning & Efficiency)

**目的:**
実験1の「独立モデル（Binary Relevance）」では、各役が互いに独立していると仮定しており、「断么九（タンヤオ）と平和（ピンフ）は複合しやすい」「七対子（チートイツ）と対々和（トイトイ）は共存しない」といった**役同士の相関関係 (Label Correlation)** を学習できていない。
本実験では、全役を単一のモデルで同時に学習する**マルチラベル学習 (Multi-label Learning)** を導入し、相関関係の考慮による予測精度の向上と、学習・推論プロセスの効率化を実証する。

**手法:**

- **モデル構造 (Shared Backbone MLP):**
- 実験1と同じ6層MLPをバックボーン（特徴抽出部）として共有する。
- 最終出力層のみを変更し、予測対象となる37役に対応した37個の出力ノードを持つ単一のネットワークとする。

- **損失関数 (Loss Function):**
- 各クラス（役）に対して独立してシグモイド関数を適用し、バイナリクロスエントロピー誤差を計算する `BCEWithLogitsLoss` を使用する。これにより、一つの入力に対して複数の役が正解となる（マルチラベル）状況に対応する。
- 数式:
- (: バッチサイズ, : クラス数37, : 正解ラベル, : ロジット)

**比較・評価項目:**

1. **精度比較:** 実験1（独立モデル）と本実験（マルチラベルモデル）の Macro F1-Score を比較し、モデル構造を変えずとも学習定式化の変更のみで精度が向上することを示す。
2. **相関学習の検証:** 「複合しやすい役」や「排他関係にある役」において、特に精度改善が見られるかを分析する。
3. **計算効率:** 37個のモデルを管理する場合と、1個の統合モデルの場合での「学習時間」および「推論速度」の差を計測し、実用面での優位性（パラメータ数の削減効果）を示す。

**予想される結果と位置付け:**
マルチラベル化によって、モデルが役同士の共起パターンを学習できるため、F1-Scoreの向上が見込まれる。また、パラメータ共有により学習時間が約1/37近くまで短縮されることが期待される。本実験で構築したモデルを**「最適化されたMLPベースライン (Strong Baseline)」**と位置づけ、次に行う実験3（アーキテクチャの変更）との比較対象とする。
