# 研究計画：不完全情報ゲームにおけるマルチラベル深層学習を用いた麻雀の役予測精度の向上

## 1. 実験設定 (Experimental Setup)

本研究では、評価の信頼性と再現性を担保するため、既存研究 [1] において詳細が不明瞭であったデータセット構築条件および予測対象ラベルを厳密に定式化する。

### 1.1 データセット構築 (Dataset Construction)

既存研究 [1] は役予測に関する先駆的な研究であるが、データセットの仕様に関する記述が一部欠落しており、同一条件での完全な再現が困難である。そこで本研究では、既存研究の不明瞭な点を補完し、以下の基準に基づいてデータセットを新規に構築する。

- **データソース:**
- **既存研究の記述:** オンライン麻雀サイト「天鳳」のトッププレイヤーの牌譜（Haifu）を使用し、学習に1,400,000レコード（局面データ）を使用したとされている 。しかし、具体的な対象期間や、何試合（半荘）分から抽出されたかについては明記されていない。

- **本研究の定義:** オンライン麻雀「天鳳」鳳凰卓の2024年全対局ログ（2024年1月1日〜2024年12月31日）をプールとする。

- **抽出条件 (Data Extraction):**
- **既存研究の記述:** 「現在の状況の情報を保存する」ために472次元の配列を使用したとあるが 、流局した局を学習データに含めているか、あるいは一局のうち「どのタイミング（全打牌時か、特定の巡目か）」をサンプリングしたかについての詳細な記述がない。

- **本研究の定義:**
- **対象局:** 和了（アガリ）が発生した局のみを抽出対象とする。流局および途中流局は、最終的な正解ラベル（完成形）が不確定であるため、学習データから除外する。
- **対象局面:** 和了したプレイヤーの視点における、配牌から和了直前までの「打牌選択時」および「副露（鳴き）選択時」の全ステップを学習サンプルとして抽出する。

- **データ分割 (Data Splitting):**
- **既存研究の記述:** データの10%を検証用データセット（Validation dataset）としたと記述されているが 、テストデータ（Test dataset）の存在や、分割方法（ランダム分割か、試合単位か）についての記述がない。

- **本研究の定義:** データ量の肥大化を防ぎつつ、役の出現分布の偏りを最小限に抑えるため、2024年のログから無作為に抽出した以下の試合数（半荘数）を使用する。同一半荘内の局面が学習・評価データ間で混在することによるリークを防ぐため、分割は必ず半荘単位で行う。
- **Train (学習):** 80,000 半荘
- **Valid (検証):** 10,000 半荘（モデル選択・ハイパーパラメータ調整用）
- **Test (評価):** 10,000 半荘（最終性能評価用）

### 1.2 予測対象ラベルの定義と分類基準

麻雀における和了役は、その成立要因に基づき、プレイヤーの戦略的意図が介在する「構造的・意志的役」と、不可制御な確率事象に依存する「事象的役（偶然役）」に大別できる。本研究では、現状の局面情報からプレイヤーの手牌構成の意図（構想）を推定することを目的とするため、以下の基準に従い予測対象を選定する。

#### A. 予測対象とする役 (Included Targets: 37種)

プレイヤーの手牌構築および能動的な意思決定によって制御可能な成分を予測対象（正解ラベル）とする。

1. **構造的役 (Structural Yaku):** 手牌の面子構成の論理的帰結として成立する役。
   - **1飜:** 断幺九、平和、一盃口、役牌（白・發・中・自風・場風）。
   - **2飜:** 混全帯幺九、一気通貫、三色同順、三色同刻、三槓子、対々和、三暗刻、小三元、混老頭、七対子。
   - **3飜以上:** 二盃口、純全帯幺九、混一色、清一色。
   - **役満:** 四暗刻、大三元、緑一色、字一色、小四喜、大四喜、清老頭、四槓子、九蓮宝燈、国士無双。
   - ※役満は出現頻度が極めて低いものの、手牌構造における明確な完成形（目標）を示すため、本研究では評価対象に含める。

2. **意思表示役 (Volitional Yaku):** プレイヤーの能動的な宣言、またはそれに基づく戦略的選択によって成立する役。
   - 立直、両立直。

3. **可視的情報 (Visible Value):** 厳密には役ではないが、局面から視認可能であり、打点向上を目的とした手作りの指針となる要素。
   - ドラ、赤ドラ。

#### B. 除外する役 (Excluded Targets: 偶然役の定義)

本研究では、手牌の構造的特徴と役の論理的関係を正確に学習させるため、以下の「客観的決定論」に基づき、一部の役を予測対象から除外する。

1. **事象的依存性 (Event Dependency) による除外基準:**
   和了役の成立条件が、プレイヤー自身の「手牌の組み合わせ」や「能動的な宣言」のみでは完結せず、牌山の配列順序や他家の打牌タイミングといった、現状の局面情報からは論理的に一意に特定不可能な外部事象に依存するものを「事象的役（偶然役）」と定義し、除外する。
   - **一発、槍槓、嶺上開花、海底摸月、河底撈魚:**
     これらは特定の「タイミング」という事象に依存しており、手牌の構造的な完成度（Hand Structuring）とは独立した確率事象であるため。

2. **情報的不可知性 (Information Observability) による除外基準:**
   和了時点まで情報が秘匿されており、プレイヤーが観測可能な情報（手牌、河、公開されたドラ表示牌）からは論理的に導出不可能な情報を除外する。
   - **裏ドラ:**
     裏ドラの期待値を考慮した打牌選択は戦略として存在するが、裏ドラの成立自体は「和了後に初めて開示される隠匿情報」に基づいている。これを予測タスクに含めることは、モデルに対して論理的推論ではなく、牌山の深層にある隠匿変数の「推測（当てずっぽう）」を強いることになり、手牌構成の学習におけるS/N比（信号対雑音比）を著しく低下させるためである。

3. **戦略的非介入性 (Non-Agentic Factors) による除外基準:**
   配牌時または局の開始時に決定し、プレイヤーの思考や手作りが介在する余地のないもの。
   - **天和、地和、人和:**
     これらは純粋な初期状態の配牌確率に依存し、本研究の主眼である「中盤以降の打牌選択における役の構想力」の評価に寄与しないため。

### 1.3 評価指標 (Metrics)

- **Macro F1-Score:** 役ごとの出現頻度は極めて不均衡（例: 断么九と三色同刻の差）であるため、単純な正解率 (Accuracy) ではなく、全クラスのF1スコアの算術平均を最重要指標とする。
- **Exact Match Ratio (Structural Accuracy):** 上記定義に基づき偶然役を除外した上で、予測した役の集合が正解ラベル集合と完全に一致したサンプルの割合。これを「構想の正確さ」と定義する。
- **Comparison Metrics:** 既存研究との比較のため、特定の主要9役（立直, 断么九, 役牌, 混一色, ドラ等）については Accuracy, Precision, Recall を算出する。

---

## 2. 実験詳細 (Methods & Experiments)

本研究では、既存研究の数値を単に追従するのではなく、前節で定義した「厳密化されたデータセット」上で手法の比較検証を行う。

### 【実験1】 現代的データセットにおけるベースラインの確立 (Baseline Establishment)

**目的:**
2024年の実データおよび厳密な評価定義（偶然役の排除）の下において、既存研究の手法（40モデル独立学習）がどの程度の性能を示すかを測定する。これを本研究における改善の出発点（Baseline）として確立する。

**手法:**

- **入力データ:** 既存研究 [1] に準拠した472次元配列（手牌34種×4、河34種×4、副露、ドラ表示牌、風、リーチ状況等のフラットな結合）。
- **モデル構造:** 全結合層 (Fully Connected Layers) 6層からなる多層パーセプトロン (MLP)。
- 各層のユニット数は既存研究の設定 [1] を再現する（512, 512, 256, 256, 256, 64）。
- **学習方式 (Binary Relevance):**
- **1.2** で定義した37種の予測対象役それぞれに対し、独立した2値分類モデル（合計37個のモデル）を作成し、個別に学習を行う。
- 最適化手法およびハイパーパラメータは、Validデータを用いて調整を行う。

**予想される結果と位置付け:**
既存研究 [1] において、特定の役（例：断么九）の予測精度は約79%（F1-score 約0.68）等の値が報告されている 。しかし、これらはデータセットの条件や評価対象（偶然役の扱いや役の総数）が異なる環境での数値である。したがって、本実験で得られた数値を、現代的なデータセットおよび本研究の定義下における、役予測タスクの正当なベースラインスコアとして新たに定義する。

### 【実験2】 マルチラベル学習による役間相関の獲得と効率化 (Multi-label Learning & Efficiency)

**目的:**
実験1の「独立モデル（Binary Relevance）」では、各役が互いに独立していると仮定しており、「断么九（タンヤオ）と平和（ピンフ）は複合しやすい」「七対子（チートイツ）と対々和（トイトイ）は共存しない」といった**役同士の相関関係 (Label Correlation)** を学習できていない。
本実験では、全役を単一のモデルで同時に学習する**マルチラベル学習 (Multi-label Learning)** を導入し、相関関係の考慮による予測精度の向上と、学習・推論プロセスの効率化を実証する。

**手法:**

- **モデル構造 (Shared Backbone MLP):**
- 実験1と同じ6層MLPをバックボーン（特徴抽出部）として共有する。
- 最終出力層のみを変更し、予測対象となる37役に対応した37個の出力ノードを持つ単一のネットワークとする。

- **損失関数 (Loss Function):**
- 各クラス（役）に対して独立してシグモイド関数を適用し、バイナリクロスエントロピー誤差を計算する `BCEWithLogitsLoss` を使用する。これにより、一つの入力に対して複数の役が正解となる（マルチラベル）状況に対応する。
- 数式:
- (: バッチサイズ, : クラス数37, : 正解ラベル, : ロジット)

**比較・評価項目:**

1. **精度比較:** 実験1（独立モデル）と本実験（マルチラベルモデル）の Macro F1-Score を比較し、モデル構造を変えずとも学習定式化の変更のみで精度が向上することを示す。
2. **相関学習の検証:** 「複合しやすい役」や「排他関係にある役」において、特に精度改善が見られるかを分析する。
3. **計算効率:** 37個のモデルを管理する場合と、1個の統合モデルの場合での「学習時間」および「推論速度」の差を計測し、実用面での優位性（パラメータ数の削減効果）を示す。

**予想される結果と位置付け:**
マルチラベル化によって、モデルが役同士の共起パターンを学習できるため、F1-Scoreの向上が見込まれる。また、パラメータ共有により学習時間が約1/37近くまで短縮されることが期待される。本実験で構築したモデルを**「最適化されたMLPベースライン (Strong Baseline)」**と位置づけ、次に行う実験3（アーキテクチャの変更）との比較対象とする。
